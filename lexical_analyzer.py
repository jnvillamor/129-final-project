import re
class LexicalAnalyzer: 
  
  def __init__(self):
    # Set up the keywords and operators
    keyword_file = open("keywords.txt", "r")
    self.keywords = keyword_file.read().splitlines()
    
    self.current_input = "" # Current code input fed to Lexical Analyzer
    self.output = "" # Output of the Lexical Analyzer for .tkn file
    self.variables = [] # List of scanned variables and their data types
    self.current_data_type = "" # Flag for current data type
    self.tokens = [] # List of tokens generated by the Lexical Analyzer
    self.current_line_number = 0 # Current line number in the code
    
  def _isValidKeyword(self, input):
    # Return true if input is a keyword, false otherwise
    if input not in self.keywords: return False
    return True
    
  def _isValidVariable(self, input):
    # Regex pattern for a valid identifier (variable name)
    identifier_regex = r'[a-zA-Z][a-zA-Z0-9_]*'

    # Return true if input matches the regex pattern, false otherwise
    return bool(re.fullmatch(identifier_regex, input))
  
  def _isValidInteger(self, input):
    # Regex pattern for a valid integer (one or more digits)
    integer_regex = r'^[0-9]+$'

    # Return true if input matches the regex pattern, false otherwise
    return bool(re.fullmatch(integer_regex, input))
  
  def _storeToken(self, literal, token_type):
    # Append token to the list of tokens
    if token_type == "keyword":
      self.tokens.append(literal)
    
    if token_type == "variable":
      self.tokens.append(("IDENT", literal))
    
    if token_type == "integer":
      self.tokens.append(("INT_LIT", literal))
  
  def _storeVariable(self, variable):
    # If variable already exists in the list, do not append to the list
    for var in self.variables:
      if var.get("name") == variable: return
    
    # Store the variable in the list
    self.variables.append({
        "name": variable,
        "data_type": self.current_data_type,
        "value": 0 if self.current_data_type == "INT" else ""
    })
  
  def writeOutput(self):
    # Write the output of tokenization to a .tkn extension file
    output_file = open("output.tkn", "w")
    output_file.write(self.output)
    output_file.close()
  
  def _raiseError(self, word):
    # Append error to the list of errors
    self.variables.append({"name" : word, "data_type" : "ERROR", "value" : "Line " + str(self.current_line_number)})
    print("Error raised at line " + str(self.current_line_number) + ": " + word)

  def tokenizeInput(self, current_input):
      current_input = current_input.split("\n")
      self.current_line_number = 0
      
      # Iterate through each word on each line of the input
      for line in current_input:
        self.current_line_number += 1
        
        if line == "": continue # Ignore whitespace
        tokenized_line = "" # Temp variable to store current line being tokenized
         
        for word in line.split():
          tokenized_line += self.tokenizeWord(word) + " "
          
        self.output += tokenized_line + "\n"    
      
      # Write output after tokenization
      self.writeOutput()
                 
  def tokenizeWord(self, word):
    # Iterate through each valid lexeme and return the token
      if self._isValidKeyword(word):
        
        # Data type flag for variables
        if word == "INT":
          self.current_data_type = "INT"
        if word == "STR":
          self.current_data_type = "STR"
                  
        self._storeToken(word, "keyword")
        
        return word
      
      if self._isValidVariable(word):
        
        self._storeToken(word, "variable")
        
        self._storeVariable(word)
        
        return "IDENT"
      
      if self._isValidInteger(word):
        
        self._storeToken(word, "integer")
        
        return "INT_LIT"
      
      self._raiseError(word) # Raise error if word is not a valid keyword, variable, or integer
      
      return word # Return the word if it is not a valid lexeme
  
if __name__ == "__main__":
  lexical_analyzer = LexicalAnalyzer()